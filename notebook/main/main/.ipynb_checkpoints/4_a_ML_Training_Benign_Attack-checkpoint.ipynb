{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd042a2a-eaa1-4aa4-9cfd-90773c0ef944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de50517-f1a0-45cf-a3f7-9af5c72d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/wahba/Documents/dataset/processed/2_cicids2017_benign_attack.csv')\n",
    "\n",
    "selected_features = [\n",
    "    # Flow-level\n",
    "    'Flow Duration',\n",
    "    'Flow Packets/s',\n",
    "    'Flow Bytes/s',\n",
    "    'Flow IAT Mean',\n",
    "    'Flow IAT Max',\n",
    "    'Flow IAT Std',\n",
    "    \n",
    "    # Forward features\n",
    "    'Fwd Header Length',\n",
    "    'Fwd IAT Total',\n",
    "    'Fwd IAT Mean',\n",
    "    'Fwd IAT Max',\n",
    "    'Fwd IAT Std',\n",
    "    'Fwd Packet Length Min',\n",
    "    'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std',\n",
    "    'Subflow Fwd Bytes',\n",
    "    'Total Fwd Packets',\n",
    "    'Total Length of Fwd Packets',\n",
    "    \n",
    "    # Backward features\n",
    "    'Bwd Header Length',\n",
    "    'Bwd Packet Length Min',\n",
    "    'Bwd Packet Length Max',\n",
    "    'Bwd Packet Length Std',\n",
    "    'Bwd Packets/s',\n",
    "    'Init_Win_bytes_backward',\n",
    "    \n",
    "    # Packet-level\n",
    "    'Packet Length Mean',\n",
    "    'Packet Length Std',\n",
    "    'Packet Length Variance',\n",
    "    'Average Packet Size',\n",
    "    'PSH Flag Count',\n",
    "    'Init_Win_bytes_forward',\n",
    "    'Max Packet Length',\n",
    "\n",
    "    'Label',\n",
    "]\n",
    "\n",
    "# Keep only the selected features\n",
    "df = df[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d427ad2-6690-4d64-84a0-475320fe4ae8",
   "metadata": {},
   "source": [
    "# 1.0 Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654bcc8-3fc7-4fa9-b816-49e47a7d6cf3",
   "metadata": {},
   "source": [
    "## 1.1 Training and Testing Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619db2c0-dd81-4155-82b0-7212bcd029b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count (df)  count (train_set)  count (test_set)  proportion\n",
      "Label                                                              \n",
      "Benign     2096484            1677187            419297    0.831159\n",
      "Attack      425878             340702             85176    0.168841\n"
     ]
    }
   ],
   "source": [
    "# splitting df for training and testing using stratified split\n",
    "X = df.drop('Label', axis=1) # features\n",
    "y = df['Label'] # target\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "X_train = strat_train_set.drop(\"Label\", axis=1)\n",
    "y_train = strat_train_set[\"Label\"]\n",
    "\n",
    "X_test = strat_test_set.drop(\"Label\", axis=1)\n",
    "y_test = strat_test_set[\"Label\"]\n",
    "\n",
    "label_mapping = {'Benign': 0, 'Attack': 1}\n",
    "y_train = y_train.map(label_mapping)\n",
    "y_test  = y_test.map(label_mapping)\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    \"count (df)\": df[\"Label\"].value_counts(),\n",
    "    \"count (train_set)\": strat_train_set[\"Label\"].value_counts(),\n",
    "    \"count (test_set)\": strat_test_set[\"Label\"].value_counts(),\n",
    "    \"proportion\": strat_train_set[\"Label\"].value_counts(normalize=True),\n",
    "})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdc198",
   "metadata": {},
   "source": [
    "## 1.2 Feature Scaling for KNN using Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17085898-c99a-40ae-a18f-765d3c1d55f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count  proportion\n",
      "Label                     \n",
      "0      1677187    0.831159\n",
      "1       340702    0.168841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/wahba/Documents/model/binary_classification/robust_scaler.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbscaler = RobustScaler()\n",
    "\n",
    "# fit and transform training data, transform testing data\n",
    "X_train_scaled = rbscaler.fit_transform(X_train)\n",
    "X_test_scaled = rbscaler.transform(X_test)\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    \"count\": y_train.value_counts(),\n",
    "    \"proportion\": y_train.value_counts(normalize=True)\n",
    "})\n",
    ")\n",
    "\n",
    "joblib.dump(rbscaler, '/home/wahba/Documents/model/binary_classification/robust_scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911563c-298b-4234-bfdb-2929960e8fbd",
   "metadata": {},
   "source": [
    "## 1.3 Undersampling Benign class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c448254-6826-44f2-a75b-dc11aa0adf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count  proportion\n",
      "Label                    \n",
      "0      340702         0.5\n",
      "1      340702         0.5\n"
     ]
    }
   ],
   "source": [
    "attack_count = y_train[y_train == 1].shape[0]\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy={0: attack_count},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "X_train_scaled_resampled, y_train_scaled_resampled = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    \"count\": y_train_resampled.value_counts(),\n",
    "    \"proportion\": y_train_resampled.value_counts(normalize=True)\n",
    "})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755b174-f4db-4cc0-b7be-11a649dbe7c3",
   "metadata": {},
   "source": [
    "# 2.0 Machine Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672d4b0-e8f9-41ce-9e77-87c9afe600b8",
   "metadata": {},
   "source": [
    "## 2.1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae03609-1881-47cc-abbb-8368bf937e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/wahba/Documents/model/binary_classification/rf_binary.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=30, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "cv_scores_rf = cross_val_score(rf, X_train_resampled, y_train_resampled, cv=5, n_jobs=-1)\n",
    "joblib.dump(rf, '/home/wahba/Documents/model/binary_classification/rf_binary.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128c19f-72d0-4c73-bc98-41002bc9e082",
   "metadata": {},
   "source": [
    "## 2.2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b439aaca-4c10-4efa-9ab2-f1878372cbea",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[07:34:36] /croot/xgboost-split_1749630910898/work/src/objective/regression_obj.cu:54: Check failed: info.labels.Size() == preds.Size() (2017889 vs. 4035778) : Invalid shape of labels.\nStack trace:\n  [bt] (0) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x207b04) [0x79eecd5eeb04]\n  [bt] (1) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x89aecb) [0x79eecdc81ecb]\n  [bt] (2) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x8ad983) [0x79eecdc94983]\n  [bt] (3) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x631076) [0x79eecda18076]\n  [bt] (4) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x79eecd5f6f8c]\n  [bt] (5) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/../../libffi.so.8(+0xa052) [0x79ef1138f052]\n  [bt] (6) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/../../libffi.so.8(+0x8925) [0x79ef1138d925]\n  [bt] (7) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x79ef1138e06e]\n  [bt] (8) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x91e7) [0x79ef0fc761e7]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m xgb \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[1;32m      2\u001b[0m     subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \n\u001b[1;32m      3\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     11\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m cv_scores_xgb \u001b[38;5;241m=\u001b[39m cross_val_score(xgb, X_train_resampled, y_train_resampled, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(xgb, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/wahba/Documents/model/binary_classification/xgb_binary.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/sklearn.py:1682\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1660\u001b[0m model, metric, params, feature_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[1;32m   1661\u001b[0m     xgb_model, params, feature_weights\n\u001b[1;32m   1662\u001b[0m )\n\u001b[1;32m   1663\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1664\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1665\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1680\u001b[0m )\n\u001b[0;32m-> 1682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:2246\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:310\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [07:34:36] /croot/xgboost-split_1749630910898/work/src/objective/regression_obj.cu:54: Check failed: info.labels.Size() == preds.Size() (2017889 vs. 4035778) : Invalid shape of labels.\nStack trace:\n  [bt] (0) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x207b04) [0x79eecd5eeb04]\n  [bt] (1) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x89aecb) [0x79eecdc81ecb]\n  [bt] (2) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x8ad983) [0x79eecdc94983]\n  [bt] (3) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(+0x631076) [0x79eecda18076]\n  [bt] (4) /home/wahba/miniconda3/envs/ml1/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x79eecd5f6f8c]\n  [bt] (5) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/../../libffi.so.8(+0xa052) [0x79ef1138f052]\n  [bt] (6) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/../../libffi.so.8(+0x8925) [0x79ef1138d925]\n  [bt] (7) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x79ef1138e06e]\n  [bt] (8) /home/wahba/miniconda3/envs/ml1/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x91e7) [0x79ef0fc761e7]\n\n"
     ]
    }
   ],
   "source": [
    "xgb = xgb.XGBClassifier(\n",
    "    subsample=1.0, \n",
    "    n_estimators=100, \n",
    "    min_child_weight=1, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.2, \n",
    "    colsample_bytree=1.0, \n",
    "\tobjective='binary:logistic', \n",
    "    num_class=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "cv_scores_xgb = cross_val_score(xgb, X_train_resampled, y_train_resampled, cv=5, n_jobs=-1)\n",
    "joblib.dump(xgb, '/home/wahba/Documents/model/binary_classification/xgb_binary.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b63f9-937e-4897-bfd8-80ffdc9a24ec",
   "metadata": {},
   "source": [
    "## 2.3. K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec92730-e001-47dd-869f-51676ef96c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(weights='distance', n_neighbors=3, n_jobs=-1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_knn = cross_val_score(knn, X_train_scaled_resampled, y_train_scaled_resampled, cv=5, n_jobs=-1)\n",
    "joblib.dump(knn, '/home/wahba/Documents/model/binary_classification/knn_binary.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac5025-d842-48d8-95ea-67bf1c634982",
   "metadata": {},
   "source": [
    "# 3.0 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072c026-069f-41fc-9ee3-0f8a1b5ea6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rf, xgb, knn]\n",
    "cv_scores = [cv_scores_rf, cv_scores_xgb, cv_scores_knn]\n",
    "\n",
    "for i in range(len(models)): \n",
    "    # 1. Cross-validation scores (you already have this)\n",
    "    print(f'''\n",
    "            ===============================\n",
    "            === Model {i+1} Evaluation ===\n",
    "            ===============================\n",
    "          ''')\n",
    "    print(\"Cross-Validation Scores:\")\n",
    "    print(f\"CV Scores: {cv_scores[i]}\")\n",
    "    print(f\"Mean CV Score: {cv_scores[i].mean():.4f} (+/- {cv_scores[i].std() * 2:.4f})\")\n",
    "\n",
    "    # 2. Predictions on test set\n",
    "    y_pred = models[i].predict(X_test if i != 2 else X_test_scaled)  # Use scaled data for KNN\n",
    "    y_pred_proba = models[i].predict_proba(X_test if i != 2 else X_test_scaled)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "    # 3. Basic metrics\n",
    "    print(\"\\n=== Test Set Performance ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "    print(f\"Average Precision (PR-AUC): {average_precision_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "    # 4. Classification report (detailed per-class metrics)\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # 5. Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(cm)\n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Class 0', 'Class 1'],\n",
    "                yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # 6. ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc_score(y_test, y_pred_proba):.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 7. Compare training vs test performance (check for overfitting)\n",
    "    y_train_pred = models[i].predict(X_train_resampled if i != 2 else X_train_scaled_resampled)\n",
    "    print(\"\\n=== Training vs Test Performance ===\")\n",
    "    print(f\"Training Accuracy: {accuracy_score(y_train_resampled, y_train_pred):.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Training F1: {f1_score(y_train_resampled, y_train_pred):.4f}\")\n",
    "    print(f\"Test F1: {f1_score(y_test, y_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
