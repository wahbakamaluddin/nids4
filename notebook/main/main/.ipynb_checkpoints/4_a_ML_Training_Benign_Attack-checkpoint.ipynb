{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd042a2a-eaa1-4aa4-9cfd-90773c0ef944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wahba/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de50517-f1a0-45cf-a3f7-9af5c72d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/wahba/Documents/dataset/processed/2_cicids2017_benign_attack.csv')\n",
    "\n",
    "selected_features = [\n",
    "    # Flow-level\n",
    "    'Flow Duration',\n",
    "    'Flow Packets/s',\n",
    "    'Flow Bytes/s',\n",
    "    'Flow IAT Mean',\n",
    "    'Flow IAT Max',\n",
    "    'Flow IAT Std',\n",
    "    \n",
    "    # Forward features\n",
    "    'Fwd Header Length',\n",
    "    'Fwd IAT Total',\n",
    "    'Fwd IAT Mean',\n",
    "    'Fwd IAT Max',\n",
    "    'Fwd IAT Std',\n",
    "    'Fwd Packet Length Min',\n",
    "    'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std',\n",
    "    'Subflow Fwd Bytes',\n",
    "    'Total Fwd Packets',\n",
    "    'Total Length of Fwd Packets',\n",
    "    \n",
    "    # Backward features\n",
    "    'Bwd Header Length',\n",
    "    'Bwd Packet Length Min',\n",
    "    'Bwd Packet Length Max',\n",
    "    'Bwd Packet Length Std',\n",
    "    'Bwd Packets/s',\n",
    "    'Init_Win_bytes_backward',\n",
    "    \n",
    "    # Packet-level\n",
    "    'Packet Length Mean',\n",
    "    'Packet Length Std',\n",
    "    'Packet Length Variance',\n",
    "    'Average Packet Size',\n",
    "    'PSH Flag Count',\n",
    "    'Init_Win_bytes_forward',\n",
    "    'Max Packet Length',\n",
    "\n",
    "    'Label',\n",
    "]\n",
    "\n",
    "# Keep only the selected features\n",
    "df = df[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d427ad2-6690-4d64-84a0-475320fe4ae8",
   "metadata": {},
   "source": [
    "# 1.0 Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654bcc8-3fc7-4fa9-b816-49e47a7d6cf3",
   "metadata": {},
   "source": [
    "## 1.1 Training and Testing Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619db2c0-dd81-4155-82b0-7212bcd029b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count (df)  count (train_set)  count (test_set)  proportion\n",
      "Label                                                              \n",
      "Benign     2096484            1677187            419297    0.831159\n",
      "Attack      425878             340702             85176    0.168841\n"
     ]
    }
   ],
   "source": [
    "# splitting df for training and testing using stratified split\n",
    "X = df.drop('Label', axis=1) # features\n",
    "y = df['Label'] # target\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "X_train = strat_train_set.drop(\"Label\", axis=1)\n",
    "y_train = strat_train_set[\"Label\"]\n",
    "\n",
    "X_test = strat_test_set.drop(\"Label\", axis=1)\n",
    "y_test = strat_test_set[\"Label\"]\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    \"count (df)\": df[\"Label\"].value_counts(),\n",
    "    \"count (train_set)\": strat_train_set[\"Label\"].value_counts(),\n",
    "    \"count (test_set)\": strat_test_set[\"Label\"].value_counts(),\n",
    "    \"proportion\": strat_train_set[\"Label\"].value_counts(normalize=True),\n",
    "})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdc198",
   "metadata": {},
   "source": [
    "## 1.2 Feature Scaling for KNN using Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17085898-c99a-40ae-a18f-765d3c1d55f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count  proportion\n",
      "Label                      \n",
      "Benign  1677187    0.831159\n",
      "Attack   340702    0.168841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/wahba/Documents/model/binary_classification/robust_scaler.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbscaler = RobustScaler()\n",
    "\n",
    "# fit and transform training data, transform testing data\n",
    "X_train_scaled = rbscaler.fit_transform(X_train)\n",
    "X_test_scaled = rbscaler.transform(X_test)\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    \"count\": y_train.value_counts(),\n",
    "    \"proportion\": y_train.value_counts(normalize=True)\n",
    "})\n",
    ")\n",
    "\n",
    "joblib.dump(rbscaler, '/home/wahba/Documents/model/binary_classification/robust_scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911563c-298b-4234-bfdb-2929960e8fbd",
   "metadata": {},
   "source": [
    "## 1.3 Undersampling Benign class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c448254-6826-44f2-a75b-dc11aa0adf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_count = y_train[y_train == 'Attack'].shape[0]\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy={'Benign': attack_count},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "X_train_scaled_resampled, y_train_scaled_resampled = rus.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755b174-f4db-4cc0-b7be-11a649dbe7c3",
   "metadata": {},
   "source": [
    "# 2.0 Machine Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672d4b0-e8f9-41ce-9e77-87c9afe600b8",
   "metadata": {},
   "source": [
    "## 2.1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae03609-1881-47cc-abbb-8368bf937e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/wahba/Documents/model/binary_classification/rf_binary.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=30, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "cv_scores_rf = cross_val_score(rf, X_train_resampled, y_train_resampled, cv=5, n_jobs=-1)\n",
    "joblib.dump(rf, '/home/wahba/Documents/model/binary_classification/rf_binary.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128c19f-72d0-4c73-bc98-41002bc9e082",
   "metadata": {},
   "source": [
    "## 2.2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439aaca-4c10-4efa-9ab2-f1878372cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wahba/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wahba/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wahba/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wahba/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wahba/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    'Benign': 0,\n",
    "    'Attack': 1,\n",
    "}\n",
    "y_train_mapped = y_train.map(label_mapping)\n",
    "y_test_mapped = y_test.map(label_mapping)\n",
    "\n",
    "xgb = xgb.XGBClassifier(\n",
    "    subsample=1.0, \n",
    "    n_estimators=100, \n",
    "    min_child_weight=1, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.2, \n",
    "    colsample_bytree=1.0, \n",
    "\tobjective='multi:softmax', \n",
    "    num_class=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "\n",
    "xgb.fit(X_train, y_train_mapped)\n",
    "cv_scores_xgb = cross_val_score(xgb, X_train, y_train_mapped, cv=5, n_jobs=-1)\n",
    "joblib.dump(xgb, '/home/wahba/Documents/model/binary_classification/xgb_binary.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b63f9-937e-4897-bfd8-80ffdc9a24ec",
   "metadata": {},
   "source": [
    "## 2.3. K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec92730-e001-47dd-869f-51676ef96c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(weights='distance', n_neighbors=3, n_jobs=-1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_knn = cross_val_score(knn, X_train_scaled_resampled, y_train_scaled_resampled, cv=5, n_jobs=-1)\n",
    "joblib.dump(knn, '/home/wahba/Documents/model/binary_classification/knn_binary.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac5025-d842-48d8-95ea-67bf1c634982",
   "metadata": {},
   "source": [
    "# 3.0 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072c026-069f-41fc-9ee3-0f8a1b5ea6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rf, xgb, knn]\n",
    "cv_scores = [cv_scores_rf, cv_scores_xgb, cv_scores_knn]\n",
    "\n",
    "for i in range(len(models)): \n",
    "    # 1. Cross-validation scores (you already have this)\n",
    "    print(f'''\n",
    "            ===============================\n",
    "            === Model {i+1} Evaluation ===\n",
    "            ===============================\n",
    "          ''')\n",
    "    print(\"Cross-Validation Scores:\")\n",
    "    print(f\"CV Scores: {cv_scores[i]}\")\n",
    "    print(f\"Mean CV Score: {cv_scores[i].mean():.4f} (+/- {cv_scores[i].std() * 2:.4f})\")\n",
    "\n",
    "    # 2. Predictions on test set\n",
    "    y_pred = models[i].predict(X_test if i != 2 else X_test_scaled)  # Use scaled data for KNN\n",
    "    y_pred_proba = models[i].predict_proba(X_test if i != 2 else X_test_scaled)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "    # 3. Basic metrics\n",
    "    print(\"\\n=== Test Set Performance ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "    print(f\"Average Precision (PR-AUC): {average_precision_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "    # 4. Classification report (detailed per-class metrics)\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # 5. Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(cm)\n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Class 0', 'Class 1'],\n",
    "                yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # 6. ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc_score(y_test, y_pred_proba):.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 7. Compare training vs test performance (check for overfitting)\n",
    "    y_train_pred = models[i].predict(X_train_resampled if i != 2 else X_train_scaled_resampled)\n",
    "    print(\"\\n=== Training vs Test Performance ===\")\n",
    "    print(f\"Training Accuracy: {accuracy_score(y_train_resampled, y_train_pred):.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Training F1: {f1_score(y_train_resampled, y_train_pred):.4f}\")\n",
    "    print(f\"Test F1: {f1_score(y_test, y_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
