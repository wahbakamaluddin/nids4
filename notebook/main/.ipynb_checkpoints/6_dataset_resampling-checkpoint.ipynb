{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2262dd59-b2cb-4d6f-9931-11daeeffe32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wahba/miniconda3/envs/ml1/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619db2c0-dd81-4155-82b0-7212bcd029b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Fwd IAT TotalLabel'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m      3\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBwd Packet Length Std\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBwd Packet Length Mean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Keep only the selected features\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# splitting df for training and testing using stratified split\u001b[39;00m\n\u001b[1;32m     25\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# features\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/pandas/core/frame.py:4119\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4118\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4119\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4121\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/pandas/core/indexes/base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml1/lib/python3.10/site-packages/pandas/core/indexes/base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Fwd IAT TotalLabel'] not in index\""
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/wahba/Documents/nids5/test/dataset/3_Full/attack_and_benign.csv')\n",
    "\n",
    "selected_features = [\n",
    "    \"Bwd Packet Length Std\",\n",
    "    \"Bwd Packet Length Mean\",\n",
    "    \"Bwd Packet Length Max\",\n",
    "    \"Total Length of Fwd Packets\",\n",
    "    \"Fwd Packet Length Max\",\n",
    "    \"Fwd Packet Length Mean\",\n",
    "    \"Fwd IAT Std\",\n",
    "    \"Total Fwd Packets\",\n",
    "    \"Fwd Packet Length Std\",\n",
    "    \"Flow IAT Max\",\n",
    "    \"Flow Bytes/s\",\n",
    "    \"Flow IAT Std\",\n",
    "    \"Bwd Packet Length Min\",\n",
    "    \"Fwd IAT Total\",\n",
    "    \"Label\",\n",
    "]\n",
    "\n",
    "# Keep only the selected features\n",
    "df = df[selected_features]\n",
    "\n",
    "# splitting df for training and testing using stratified split\n",
    "X = df.drop('Label', axis=1) # features\n",
    "y = df['Label'] # target\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "X_train = strat_train_set.drop(\"Label\", axis=1)\n",
    "y_train = strat_train_set[\"Label\"]\n",
    "\n",
    "X_test = strat_test_set.drop(\"Label\", axis=1)\n",
    "y_test = strat_test_set[\"Label\"]\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    \"count (df)\": df[\"Label\"].value_counts(),\n",
    "    \"count (train_set)\": strat_train_set[\"Label\"].value_counts(),\n",
    "    \"count (test_set)\": strat_test_set[\"Label\"].value_counts(),\n",
    "    \"proportion\": strat_train_set[\"Label\"].value_counts(normalize=True),\n",
    "})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17085898-c99a-40ae-a18f-765d3c1d55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbscaler = RobustScaler()\n",
    "\n",
    "# fit and transform training data, transform testing data\n",
    "X_train_scaled = rbscaler.fit_transform(X_train)\n",
    "X_test_scaled = rbscaler.transform(X_test)\n",
    "\n",
    "joblib.dump(rbscaler, '/home/wahba/Documents/nids5/test/model/binary/robust_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08d77e-e2c8-48aa-abf9-08c5c05f899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({\n",
    "    \"count\": y_train.value_counts(),\n",
    "    \"proportion\": y_train.value_counts(normalize=True)\n",
    "})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f732df9-dda7-4a50-9636-c7543ddd6d7b",
   "metadata": {},
   "source": [
    "# Undersampling BENIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c82e31-67f8-45fa-b456-92d9f2cb44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the undersampling for the clean df\n",
    "X_train_resampled, y_train_resampled = RandomUnderSampler(sampling_strategy={'BENIGN': 500000}, random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "# Initializing the undersampling for the scaled df\n",
    "X_train_scaled, y_train_scaled = RandomUnderSampler(sampling_strategy={'BENIGN': 500000}, random_state=42).fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282b86c-930b-47f4-b0bb-56d164b31846",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({\n",
    "    \"count\": y_train_resampled.value_counts(),\n",
    "    \"proportion\": y_train_resampled.value_counts(normalize=True)\n",
    "})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755b174-f4db-4cc0-b7be-11a649dbe7c3",
   "metadata": {},
   "source": [
    "# 2. Machine Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672d4b0-e8f9-41ce-9e77-87c9afe600b8",
   "metadata": {},
   "source": [
    "## 2.1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b40c4d-4325-40b0-8afa-ef024ef34683",
   "metadata": {},
   "source": [
    "## 2.1.1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b066b96-e23d-4b8d-9722-448eeef0c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Defining the parameters for the Random Forest Classifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "Creating the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Saving results with the standard parameters\n",
    "cv_sc_rf = cross_val_score(rf_model, X_train_resampled, y_train_resampled, cv=3, n_jobs=-1)\n",
    "cv_sc_rf = np.mean(cv_sc_rf)\n",
    "\n",
    "# Apply RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_grid, n_iter=20, cv=3, n_jobs=-1, verbose=2)\n",
    "random_search_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "print(f'Best Parameters: {random_search_rf.best_params_}')\n",
    "print(f\"Best Cross-Validation Score: {random_search_rf.best_score_}\")\n",
    "print(f\"Cross-Validation from Standard: {cv_sc_rf}\")\n",
    "\n",
    "best_params_rf = random_search_rf.best_params_ if random_search_rf.best_score_ > cv_sc_rf else None\n",
    "\n",
    "del random_search_rf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82cd75-1a27-41a5-954a-38b9192e61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Defining the parameters for the Random Forest Classifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "Creating the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Saving results with the standard parameters\n",
    "cv_sc_rf = cross_val_score(rf_model, X_train_resampled, y_train_resampled, cv=3, n_jobs=-1)\n",
    "cv_sc_rf = np.mean(cv_sc_rf)\n",
    "\n",
    "# Apply RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_grid, n_iter=20, cv=3, n_jobs=-1, verbose=2)\n",
    "random_search_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "print(f'Best Parameters: {random_search_rf.best_params_}')\n",
    "print(f\"Best Cross-Validation Score: {random_search_rf.best_score_}\")\n",
    "print(f\"Cross-Validation from Standard: {cv_sc_rf}\")\n",
    "\n",
    "best_params_rf = random_search_rf.best_params_ if random_search_rf.best_score_ > cv_sc_rf else None\n",
    "\n",
    "del random_search_rf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae03609-1881-47cc-abbb-8368bf937e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = {'n_estimators': 150, \n",
    "                'min_samples_split': 2, \n",
    "                'min_samples_leaf': 2, \n",
    "                'max_features': 'sqrt', \n",
    "                'max_depth': 30}\n",
    "cv = 5\n",
    "n_jobs = -1\n",
    "random_state = 42\n",
    "\n",
    "measurement_rf = {}\n",
    "\n",
    "rf_model = RandomForestClassifier(**best_params_rf, random_state=random_state, n_jobs=n_jobs)\n",
    "\n",
    "# Function to monitor CPU usage during training\n",
    "cpu_usage = []\n",
    "stop_flag = threading.Event()\n",
    "\n",
    "def monitor_cpu():\n",
    "    while not stop_flag.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "# Function to train the model\n",
    "def train_model():\n",
    "    rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "try:\n",
    "    # Start CPU monitoring in a separate thread\n",
    "    cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "    cpu_thread.start()\n",
    "\n",
    "    # Measure memory usage and training time\n",
    "    start_time = time.time()\n",
    "    train_memory_rf = max(memory_usage((train_model,)))  # Measure peak memory usage\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Stop CPU monitoring\n",
    "    stop_flag.set()\n",
    "    cpu_thread.join()\n",
    "\n",
    "    # Add measurements\n",
    "    measurement_rf['Memory Usage (MB)'] = train_memory_rf\n",
    "    measurement_rf['Training Time (s)'] = training_time\n",
    "    measurement_rf['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "    measurement_rf['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores_rf = cross_val_score(rf_model, X_train_resampled, y_train_resampled, cv=cv, n_jobs=n_jobs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Random Forest training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05fa51-2a16-4611-8070-31c73342974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1.3. Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c7404-00ae-4515-b500-769ffc50948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-validation average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207889e-254b-4ed7-9de4-142e6004531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model performance on the cross validation set vs accuracy on the test set\n",
    "cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "print(f'Cross validation average score: {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18111014-8975-4301-aafd-8846f4b60be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02185f45-6b8e-4735-ba26-b602a1c3273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Accuracy on the test set: {accuracy_rf:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744acaf-8911-4b9b-88c9-859be6a4828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computational Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948ac79-1e04-4976-9957-b7fe0c733abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resource measurements:\", measurement_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a411904-07ce-42cd-ae89-55678e74fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aea3a5-a61b-47d6-af0d-5abb50d84500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model via confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', xticklabels=rf_model.classes_, yticklabels=rf_model.classes_, cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title('Random ForestConfusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a457aa6-9578-43b7-9cd6-f8b0a6171ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77bfde-91df-47d8-afc3-804f417f5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715caab-dfdb-4e44-b795-4842fa5ce98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1.4 Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91618f4a-e707-4ced-9a6a-20fe64a06ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_model, '/home/wahba/Documents/nids5/test/model/binary/rf_binary2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4296315-f9bf-43df-b2f5-c52b350e800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37acbe-df5d-4a16-9b42-db4c1db814b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2.1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be182a-521e-4cc1-bcee-0763480c1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2.1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1522ab-8405-4cb6-830a-9a9cc6072bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Defining the parameter grid for XGBoost\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.2, 0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "}\n",
    "\n",
    "# XGBoost's `multi:softmax` objective requires numerical labels for classification. Therefore, a mapping is necessary to convert categorical labels into numerical values before training the model.\n",
    "# # Creating the XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(y_train_resampled.unique()), random_state=42, n_jobs=-1)\n",
    "\n",
    "# Custom mapping for the attack types\n",
    "label_mapping = {\n",
    "    'Normal Traffic': 0,\n",
    "    'DoS': 1,\n",
    "    'DDoS': 2,\n",
    "    'Port Scanning': 3,\n",
    "    'Brute Force': 4,\n",
    "    'Web Attacks': 5,\n",
    "    'Bots': 6\n",
    "}\n",
    "y_train_resampled_mapped = y_train_resampled.map(label_mapping)\n",
    "y_test_mapped = y_test.map(label_mapping)\n",
    "\n",
    "# Saving results with the standard parameters\n",
    "cv_sc_xgb = cross_val_score(xgb_model, X_train_resampled, y_train_resampled_mapped, cv=3, n_jobs=-1)\n",
    "cv_sc_xgb = np.mean(cv_sc_xgb)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search_xgb = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=30, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search_xgb.fit(X_train_resampled, y_train_resampled_mapped)\n",
    "\n",
    "# Best parameters found by RandomizedSearchCV\n",
    "print(f'Best Parameters for XGBoost: {random_search_xgb.best_params_}')\n",
    "print(f\"Best Cross-Validation Score: {random_search_xgb.best_score_}\")\n",
    "print(f\"Cross-Validation from Standard: {cv_sc_xgb}\")\n",
    "\n",
    "best_params_xgb = random_search_xgb.best_params_ if random_search_xgb.best_score_ > cv_sc_xgb else None\n",
    "\n",
    "del random_search_xgb\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b141612-bbcb-49b6-8ba3-10bdfc9617b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Best Parameters for XGBoost: {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
    "Best Cross-Validation Score: 0.9990827488980495\n",
    "Cross-Validation from Standard: 0.9990851282783\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439aaca-4c10-4efa-9ab2-f1878372cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the XGBoost Classifier\n",
    "# xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(y_train_resampled.unique()), random_state=42, n_jobs=-1)\n",
    "\n",
    "# Custom mapping for the attack types\n",
    "label_mapping = {\n",
    "    'BENIGN': 0,\n",
    "    'Attack': 1,\n",
    "}\n",
    "y_train_resampled_mapped = y_train_resampled.map(label_mapping)\n",
    "y_test_mapped = y_test.map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877d3c6-10f7-4c8f-8eb5-1ba68f87cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2.2. Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774e635-b8f9-4e89-871d-2d29dffac3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = {'subsample': 1.0, \n",
    "\t\t\t\t'n_estimators': 100, \n",
    "\t\t\t\t'min_child_weight': 1, \n",
    "\t\t\t\t'max_depth': 6, \n",
    "\t\t\t\t'learning_rate': 0.2, \n",
    "\t\t\t\t'colsample_bytree': 1.0}\n",
    "cv = 5\n",
    "n_jobs = -1\n",
    "random_state = 42\n",
    "\n",
    "measurement_xgb = {}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**best_params_xgb, \n",
    "\t\t\t\t\t\t\tobjective='multi:softmax', \n",
    "\t\t\t\t\t\t\tnum_class=len(y_train_resampled_mapped.unique()), \n",
    "\t\t\t\t\t\t\trandom_state = random_state, \n",
    "\t\t\t\t\t\t\tn_jobs = n_jobs)\n",
    "\n",
    "# Function to monitor CPU usage during training\n",
    "cpu_usage = []\n",
    "stop_flag = threading.Event()\n",
    "\n",
    "def monitor_cpu():\n",
    "    while not stop_flag.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "# Function to train the model\n",
    "def train_model():\n",
    "    xgb_model.fit(X_train_resampled, y_train_resampled_mapped)\n",
    "\n",
    "try:\n",
    "    # Start CPU monitoring in a separate thread\n",
    "    cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "    cpu_thread.start()\n",
    "\n",
    "    # Measure memory usage and training time\n",
    "    start_time = time.time()\n",
    "    train_memory_xgb = max(memory_usage((train_model,)))  # Measure peak memory usage\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Stop CPU monitoring\n",
    "    stop_flag.set()\n",
    "    cpu_thread.join()\n",
    "\n",
    "    # Add measurements\n",
    "    measurement_xgb['Memory Usage (MB)'] = train_memory_rf\n",
    "    measurement_xgb['Training Time (s)'] = training_time\n",
    "    measurement_xgb['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "    measurement_xgb['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores_xgb = cross_val_score(xgb_model, X_train_resampled, y_train_resampled_mapped, cv = cv, n_jobs = n_jobs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Random Forest training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0fed5-9693-43af-a75d-992d6c99a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2.3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4508b-8de8-4e6f-b2fa-cb5e8238ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af3e04-dd06-4ad2-b70e-9c14b194b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model performance on the cross validation set vs accuracy on the test set\n",
    "cv_scores_mean_xgb = np.mean(cv_scores_xgb)\n",
    "print(f'Cross validation average score: {cv_scores_mean_xgb:.4f} +/- standard deviation: {np.std(cv_scores_xgb):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2524f-e6fd-40ad-bab2-eec50e4ea8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa5a55-7917-4f3c-aa44-050f0b89d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_xgb = accuracy_score(y_test_mapped, y_pred_xgb)\n",
    "print(f'Accuracy on the test set: {accuracy_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c72b8-8084-4342-a25a-7061bae2828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computational Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01f78a-9bdd-4bc8-95bb-087cb4401f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resource measurements:\", measurement_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7e4dd-56bb-4110-9c75-303697935fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ba2a8-96cc-4eea-95fa-9759d4f53032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapping the labels for visualization\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "predicted_labels = [reverse_label_mapping[pred] for pred in y_pred_xgb]\n",
    "actual_labels = sorted([reverse_label_mapping[label] for label in xgb_model.classes_])\n",
    "\n",
    "# Confusion matrix\n",
    "cm_xgb = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_xgb, annot=True, fmt='d', xticklabels=actual_labels, yticklabels=actual_labels, cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce25a41-d90e-4200-a939-3fc31c5f4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ebf51-16d8-4b93-a134-7d7574b3c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355d638-bcf8-489f-9d0c-c09c42ef4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2.3. Exporting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11cfbf2-1dbe-4a25-8043-457bbe8b1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_model, '/home/wahba/Documents/nids5/test/model/binary/xgb_binary.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406e08c-9777-4477-aa3d-bdd66b798aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3. K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38f432-0423-4085-97f0-30994730386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3.1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15774721-b349-4f0c-aaff-425ce52ff17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Defining the parameters for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "# Creating the KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# Saving results with the standard parameters\n",
    "cv_sc_knn = cross_val_score(knn_model, X_train_resampled_scaled, y_train_resampled_scaled, cv=3, n_jobs=-1)\n",
    "cv_sc_knn = np.mean(cv_sc_knn)\n",
    "\n",
    "# Apply RandomizedSearchCV\n",
    "random_search_knn = RandomizedSearchCV(estimator=knn_model, param_distributions=param_grid_knn, n_iter=6, cv=3, n_jobs=-1, verbose=2)\n",
    "random_search_knn.fit(X_train_resampled_scaled, y_train_resampled_scaled)\n",
    "\n",
    "# Get the best parameters\n",
    "print(f'Best Parameters: {random_search_knn.best_params_}')\n",
    "print(f\"Best Cross-Validation Score: {random_search_knn.best_score_}\")\n",
    "print(f\"Cross-Validation from Standard: {cv_sc_knn}\")\n",
    "\n",
    "best_params_knn = random_search_knn.best_params_ if random_search_knn.best_score_ > cv_sc_knn else None\n",
    "\n",
    "del random_search_knn\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed28f5a-129e-4464-81ee-9ece2570dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_knn = {'weights': 'distance', 'n_neighbors': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3477cd1-65f3-428a-b27d-436568caed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3.2 Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec92730-e001-47dd-869f-51676ef96c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_knn = {'weights': 'distance', 'n_neighbors': 3}\n",
    "\n",
    "cv = 5\n",
    "n_jobs = -1 # use all available processors to run neighbours search\n",
    "random_state = 42\n",
    "\n",
    "measurement_knn = {}\n",
    "\n",
    "knn_model = KNeighborsClassifier(**best_params_knn, n_jobs = n_jobs)\n",
    "\n",
    "# Function to monitor CPU usage during training\n",
    "cpu_usage = []\n",
    "stop_flag = threading.Event()\n",
    "\n",
    "def monitor_cpu():\n",
    "    while not stop_flag.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "# Function to train the model\n",
    "def train_model():\n",
    "    knn_model.fit(X_train_resampled_scaled, y_train_resampled_scaled)\n",
    "\n",
    "try:\n",
    "    # Start CPU monitoring in a separate thread\n",
    "    cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "    cpu_thread.start()\n",
    "\n",
    "    # Measure memory usage and training time\n",
    "    start_time = time.time()\n",
    "    train_memory_knn = max(memory_usage((train_model,)))  # Measure peak memory usage\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Stop CPU monitoring\n",
    "    stop_flag.set()\n",
    "    cpu_thread.join()\n",
    "\n",
    "    # Add measurements\n",
    "    measurement_knn['Memory Usage (MB)'] = train_memory_knn\n",
    "    measurement_knn['Training Time (s)'] = training_time\n",
    "    measurement_knn['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "    measurement_knn['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores_knn = cross_val_score(knn_model, X_train_resampled_scaled, y_train_resampled_scaled, cv = cv, n_jobs = n_jobs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Random Forest training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be673e4-f72a-45c1-a99a-76c7a46a3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2.3. Model Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d6abd-8977-4ac4-b0b4-f47285dae72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e5313-f210-4645-a9eb-3a0b44ef51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "# Evaluating the model performance on the cross validation set vs accuracy on the test set\n",
    "cv_scores_mean_knn = np.mean(cv_scores_knn)\n",
    "print(f'Cross validation average score: {cv_scores_mean_knn:.4f} +/- standard deviation: {np.std(cv_scores_knn):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f248155-18fe-4ec8-8df2-ad150703623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c70512-c46d-4058-8e4c-0cf35bc5ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f'Accuracy on the test set: {accuracy_knn:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd52a46-a387-477b-b6b2-fd985cf19e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19492075-a075-469d-8d63-b907011c7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resource measurements:\", measurement_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac384349-23c4-4be8-9813-1512c166b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c531dd9-cfe9-4fa7-80ad-d7edb48bbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model via confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_knn, annot=True, fmt='d', xticklabels=knn_model.classes_, yticklabels=knn_model.classes_, cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e09d5b-5e5a-46b7-ab0f-292a3b9874e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcd9ca-6aa6-4e4f-8af2-97a73139ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d74cec-8d41-4e95-947d-32d3c60adde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3.3. Exporting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a5180-a246-44b1-8f3c-43870ab85108",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(knn_model, 'D/home/wahba/Documents/nids5/test/model/binary/knn_binary.joblib'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991501f-6bdd-468b-812d-f49c8e7b2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de54e62-7f34-4644-a835-46a5c8be74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating precision, recall, and F1 score for each model\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "precision_xgb = precision_score(y_test_mapped, y_pred_xgb, average='weighted')\n",
    "recall_xgb = recall_score(y_test_mapped, y_pred_xgb, average='weighted')\n",
    "f1_xgb = f1_score(y_test_mapped, y_pred_xgb, average='weighted')\n",
    "\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='weighted')\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted')\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9537b4-e020-457d-9914-ea2da4ee7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the results dataframe\n",
    "supervised_results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost', 'KNN'],\n",
    "    'Accuracy': [accuracy_rf, accuracy_xgb, accuracy_knn],\n",
    "    'Cross Validation Mean': [cv_scores_mean_rf, cv_scores_mean_xgb, cv_scores_mean_knn],\n",
    "    'Precision': [precision_rf, precision_xgb, precision_knn],\n",
    "    'Recall': [recall_rf, recall_xgb, recall_knn],\n",
    "    'F1 Score': [f1_rf, f1_xgb, f1_knn],\n",
    "    'Memory Usage (MB)': [measurement_rf['Memory Usage (MB)'], measurement_xgb['Memory Usage (MB)'], measurement_knn['Memory Usage (MB)']],\n",
    "    'Training Time (s)': [measurement_rf['Training Time (s)'], measurement_xgb['Training Time (s)'], measurement_knn['Training Time (s)']],\n",
    "    'Peak CPU Usage (%)': [measurement_rf['Peak CPU Usage (%)'], measurement_xgb['Peak CPU Usage (%)'], measurement_knn['Peak CPU Usage (%)']],\n",
    "    'Average CPU Usage (%)': [measurement_rf['Average CPU Usage (%)'], measurement_xgb['Average CPU Usage (%)'], measurement_knn['Average CPU Usage (%)']],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55b645-e0b4-4490-b69b-fb9464aecdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the comparison for accuracy, cross-validation, and metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plotting Accuracy and Cross Validation Mean\n",
    "supervised_results.set_index('Model')[['Accuracy', 'Cross Validation Mean']].plot(kind='bar', ax=axes[0, 0], color=['skyblue', 'lightgreen'], legend=True)\n",
    "axes[0, 0].set_title('Model Comparison: Accuracy and Cross Validation Mean')\n",
    "axes[0, 0].set_ylabel('Score')\n",
    "axes[0, 0].set_xlabel('Model')\n",
    "axes[0, 0].set_ylim(0.95, 1.0)\n",
    "axes[0, 0].legend(loc='lower left')\n",
    "\n",
    "# Plotting Precision, Recall, F1 Score\n",
    "supervised_results.set_index('Model')[['Precision', 'Recall', 'F1 Score']].plot(kind='bar', ax=axes[0, 1], color=['orange', 'lightcoral', 'yellowgreen'], legend=True)\n",
    "axes[0, 1].set_title('Model Comparison: Precision, Recall, F1 Score')\n",
    "axes[0, 1].set_ylabel('Score')\n",
    "axes[0, 1].set_xlabel('Model')\n",
    "axes[0, 1].set_ylim(0.95, 1.0)\n",
    "axes[0, 1].legend(loc='lower left')\n",
    "\n",
    "# Plotting Memory Usage and Training Time\n",
    "ax1 = axes[1, 0]\n",
    "\n",
    "supervised_results.set_index('Model')['Memory Usage (MB)'].plot(\n",
    "    kind='bar', ax=ax1, color='lightblue', label='Memory Usage (MB)', width=0.6\n",
    ")\n",
    "ax1.set_ylabel('Memory Usage (MB)', color='lightblue')\n",
    "ax1.tick_params(axis='y', labelcolor='lightblue')\n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "supervised_results.set_index('Model')['Training Time (s)'].plot(\n",
    "    ax=ax2, color='lightpink', marker='o', label='Training Time (s)'\n",
    ")\n",
    "ax2.set_ylabel('Training Time (s)', color='lightpink')\n",
    "ax2.tick_params(axis='y', labelcolor='lightpink')\n",
    "\n",
    "ax1.set_title('Model Comparison: Memory Usage and Training Time')\n",
    "ax1.set_xlabel('Model')\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "# Plotting Peak and Average CPU Usage\n",
    "supervised_results.set_index('Model')[['Peak CPU Usage (%)', 'Average CPU Usage (%)']].plot(kind='bar', ax=axes[1, 1], color=['lightgreen', 'salmon'], legend=True)\n",
    "axes[1, 1].set_title('Model Comparison: CPU Usage')\n",
    "axes[1, 1].set_ylabel('Percentage')\n",
    "axes[1, 1].set_xlabel('Model')\n",
    "axes[1, 1].legend(loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
