{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066e2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cddc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df1 = pd.read_csv('/home/wahba/Documents/cicid/cicids2017/original/csv/TrafficLabelling /Wednesday-workingHours.pcap_ISCX.csv')\n",
    "df2 = pd.read_csv('/home/wahba/Documents/cicid/CICFlowMeter/data/daily/2025-11-21_Flow.csv')\n",
    "df3 = pd.read_csv('/home/wahba/Documents/nids3/tests/flow/flow_tuesday_flow_generation4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826ed2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning column names\n",
    "col_names = {col: col.strip() for col in df1.columns}\n",
    "df1.rename(columns=col_names, inplace=True)\n",
    "col_names = {col: col.strip() for col in df2.columns}\n",
    "df2.rename(columns=col_names, inplace=True)\n",
    "col_names = {col: col.strip() for col in df3.columns}\n",
    "df3.rename(columns=col_names, inplace=True)\n",
    "\n",
    "del col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c595aa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN              440031\n",
       "DoS Hulk            231073\n",
       "DoS GoldenEye        10293\n",
       "DoS slowloris         5796\n",
       "DoS Slowhttptest      5499\n",
       "Heartbleed              11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa36205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only DoS slowhttptest attacks\n",
    "df1_dos = df1[df1['Label'] == 'DoS Slowhttptest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dos['flow_key'] = (\n",
    "    df1_dos['Source IP'].astype(str) + ':' +\n",
    "    df1_dos['Source Port'].astype(str) + '-' +\n",
    "    df1_dos['Destination IP'].astype(str) + ':' +\n",
    "    df1_dos['Destination Port'].astype(str) + '-' +\n",
    "    df1_dos['Protocol'].astype(str)\n",
    "    )\n",
    "df2['flow_key'] = (\n",
    "    df2['Src IP'].astype(str) + ':' +\n",
    "    df2['Src Port'].astype(str) + '-' +\n",
    "    df2['Dst IP'].astype(str) + ':' +\n",
    "    df2['Dst Port'].astype(str) + '-' +\n",
    "    df2['Protocol'].astype(str)\n",
    "    )\n",
    "df3['Protocol'] = df3['Protocol'].replace({'TCP': 6, 'UDP': 17, 'ICMP': 1}).astype(int)\n",
    "df3['flow_key'] = (\n",
    "    df3['Source IP'].astype(str) + ':' +\n",
    "    df3['Source Port'].astype(str) + '-' +\n",
    "    df3['Destination IP'].astype(str) + ':' +\n",
    "    df3['Destination Port'].astype(str) + '-' +\n",
    "    df3['Protocol'].astype(str)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb71a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique flow keys for slowhttptest from df1\n",
    "\n",
    "slowhttptest_flow_key = df1_dos['flow_key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba510788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df2 and df3 for flows matching slowhttptest flow keys\n",
    "df2_dos = df2[df2['flow_key'].isin(slowhttptest_flow_key)]\n",
    "df3_dos = df3[df3['flow_key'].isin(slowhttptest_flow_key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08aad413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659, 85)\n",
      "(376, 58)\n"
     ]
    }
   ],
   "source": [
    "print(df2_dos.shape)\n",
    "print(df3_dos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a7538",
   "metadata": {},
   "source": [
    "# Test model prediction on flow generated by CICFLOWMETER and from CICIDS2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f77d16da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wahba/miniconda3/envs/ml2/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/wahba/miniconda3/envs/ml2/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RobustScaler from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "rf = joblib.load(\"/home/wahba/Documents/models_anacletu/xgboost.joblib\")\n",
    "xgb = joblib.load(\"/home/wahba/Documents/models_anacletu/xgboost.joblib\")\n",
    "knn = joblib.load(\"/home/wahba/Documents/models_anacletu/knn_model.joblib\")\n",
    "robust_scaler = joblib.load(\"/home/wahba/Documents/models_anacletu/robust_scaler.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1850c45",
   "metadata": {},
   "source": [
    "# Standardizing dataframes to feed to ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "965c4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing column names\n",
    "'''\n",
    "final_cols_df1 = {\n",
    "    'Source IP': 'Source IP',\n",
    "    'Destination IP': 'Destination IP',\n",
    "    'Protocol': 'Protocol',\n",
    "    'Source Port': 'Source Port',\n",
    "    'Destination Port': 'Destination Port',\n",
    "    'Flow Duration': 'Flow Duration',\n",
    "    'Total Fwd Packets': 'Total Fwd Packets',\n",
    "    'Total Length of Fwd Packets': 'Total Length of Fwd Packets',\n",
    "    'Fwd Packet Length Max': 'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Min': 'Fwd Packet Length Min',\n",
    "    'Fwd Packet Length Mean': 'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std': 'Fwd Packet Length Std',\n",
    "    'Bwd Packet Length Max': 'Bwd Packet Length Max',\n",
    "    'Bwd Packet Length Min': 'Bwd Packet Length Min',\n",
    "    'Bwd Packet Length Mean': 'Bwd Packet Length Mean',\n",
    "    'Bwd Packet Length Std': 'Bwd Packet Length Std',\n",
    "    'Flow Bytes/s': 'Flow Bytes/s',\n",
    "    'Flow Packets/s': 'Flow Packets/s',\n",
    "    'Flow IAT Mean': 'Flow IAT Mean',\n",
    "    'Flow IAT Std': 'Flow IAT Std',\n",
    "    'Flow IAT Max': 'Flow IAT Max',\n",
    "    'Flow IAT Min': 'Flow IAT Min',\n",
    "    'Fwd IAT Total': 'Fwd IAT Total',\n",
    "    'Fwd IAT Mean': 'Fwd IAT Mean',\n",
    "    'Fwd IAT Std': 'Fwd IAT Std',\n",
    "    'Fwd IAT Max': 'Fwd IAT Max',\n",
    "    'Fwd IAT Min': 'Fwd IAT Min',\n",
    "    'Bwd IAT Total': 'Bwd IAT Total',\n",
    "    'Bwd IAT Mean': 'Bwd IAT Mean',\n",
    "    'Bwd IAT Std': 'Bwd IAT Std',\n",
    "    'Bwd IAT Max': 'Bwd IAT Max',\n",
    "    'Bwd IAT Min': 'Bwd IAT Min',\n",
    "    'Fwd Header Length': 'Fwd Header Length',\n",
    "    'Bwd Header Length': 'Bwd Header Length',\n",
    "    'Fwd Packets/s': 'Fwd Packets/s',\n",
    "    'Bwd Packets/s': 'Bwd Packets/s',\n",
    "    'Min Packet Length': 'Min Packet Length',\n",
    "    'Max Packet Length': 'Max Packet Length',\n",
    "    'Packet Length Mean': 'Packet Length Mean',\n",
    "    'Packet Length Std': 'Packet Length Std',\n",
    "    'Packet Length Variance': 'Packet Length Variance',\n",
    "    'FIN Flag Count': 'FIN Flag Count',\n",
    "    'PSH Flag Count': 'PSH Flag Count',\n",
    "    'ACK Flag Count': 'ACK Flag Count',\n",
    "    'Average Packet Size': 'Average Packet Size',\n",
    "    'Subflow Fwd Bytes': 'Subflow Fwd Bytes',\n",
    "    'Init_Win_bytes_forward': 'Init_Win_bytes_forward',\n",
    "    'Init_Win_bytes_backward': 'Init_Win_bytes_backward',\n",
    "    'act_data_pkt_fwd': 'act_data_pkt_fwd',\n",
    "    'min_seg_size_forward': 'min_seg_size_forward',\n",
    "    'Active Mean': 'Active Mean',\n",
    "    'Active Max': 'Active Max',\n",
    "    'Active Min': 'Active Min',\n",
    "    'Idle Mean': 'Idle Mean',\n",
    "    'Idle Max': 'Idle Max',\n",
    "    'Idle Min': 'Idle Min'\n",
    "}\n",
    "\n",
    "final_cols_df2 = {\n",
    "    'Src IP': 'Source IP',\n",
    "    'Dst IP': 'Destination IP',\n",
    "    'Protocol': 'Protocol',\n",
    "    'Src Port': 'Source Port',\n",
    "    'Dst Port': 'Destination Port',\n",
    "    'Flow Duration': 'Flow Duration',\n",
    "    'Total Fwd Packet': 'Total Fwd Packets',\n",
    "    'Total Length of Fwd Packet': 'Total Length of Fwd Packets',\n",
    "    'Fwd Packet Length Max': 'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Min': 'Fwd Packet Length Min',\n",
    "    'Fwd Packet Length Mean': 'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std': 'Fwd Packet Length Std',\n",
    "    'Bwd Packet Length Max': 'Bwd Packet Length Max',\n",
    "    'Bwd Packet Length Min': 'Bwd Packet Length Min',\n",
    "    'Bwd Packet Length Mean': 'Bwd Packet Length Mean',\n",
    "    'Bwd Packet Length Std': 'Bwd Packet Length Std',\n",
    "    'Flow Bytes/s': 'Flow Bytes/s',\n",
    "    'Flow Packets/s': 'Flow Packets/s',\n",
    "    'Flow IAT Mean': 'Flow IAT Mean',\n",
    "    'Flow IAT Std': 'Flow IAT Std',\n",
    "    'Flow IAT Max': 'Flow IAT Max',\n",
    "    'Flow IAT Min': 'Flow IAT Min',\n",
    "    'Fwd IAT Total': 'Fwd IAT Total',\n",
    "    'Fwd IAT Mean': 'Fwd IAT Mean',\n",
    "    'Fwd IAT Std': 'Fwd IAT Std',\n",
    "    'Fwd IAT Max': 'Fwd IAT Max',\n",
    "    'Fwd IAT Min': 'Fwd IAT Min',\n",
    "    'Bwd IAT Total': 'Bwd IAT Total',\n",
    "    'Bwd IAT Mean': 'Bwd IAT Mean',\n",
    "    'Bwd IAT Std': 'Bwd IAT Std',\n",
    "    'Bwd IAT Max': 'Bwd IAT Max',\n",
    "    'Bwd IAT Min': 'Bwd IAT Min',\n",
    "    'Fwd Header Length': 'Fwd Header Length',\n",
    "    'Bwd Header Length': 'Bwd Header Length',\n",
    "    'Fwd Packets/s': 'Fwd Packets/s',\n",
    "    'Bwd Packets/s': 'Bwd Packets/s',\n",
    "    'Packet Length Min': 'Min Packet Length',\n",
    "    'Packet Length Max': 'Max Packet Length',\n",
    "    'Packet Length Mean': 'Packet Length Mean',\n",
    "    'Packet Length Std': 'Packet Length Std',\n",
    "    'Packet Length Variance': 'Packet Length Variance',\n",
    "    'FIN Flag Count': 'FIN Flag Count',\n",
    "    'PSH Flag Count': 'PSH Flag Count',\n",
    "    'ACK Flag Count': 'ACK Flag Count',\n",
    "    'Average Packet Size': 'Average Packet Size',\n",
    "    'Subflow Fwd Bytes': 'Subflow Fwd Bytes',\n",
    "    'FWD Init Win Bytes': 'Init_Win_bytes_forward',\n",
    "    'Bwd Init Win Bytes': 'Init_Win_bytes_backward',\n",
    "    'Fwd Act Data Pkts': 'act_data_pkt_fwd',\n",
    "    'Fwd Seg Size Min': 'min_seg_size_forward',\n",
    "    'Active Mean': 'Active Mean',\n",
    "    'Active Max': 'Active Max',\n",
    "    'Active Min': 'Active Min',\n",
    "    'Idle Mean': 'Idle Mean',\n",
    "    'Idle Max': 'Idle Max',\n",
    "    'Idle Min': 'Idle Min'\n",
    "}\n",
    "'''\n",
    "\n",
    "final_columns_df1 = {\n",
    "    'Destination Port': 'Destination Port',\n",
    "    'Flow Duration': 'Flow Duration',\n",
    "    'Total Fwd Packets': 'Total Fwd Packets',\n",
    "    'Total Length of Fwd Packets': 'Total Length of Fwd Packets',\n",
    "    'Fwd Packet Length Max': 'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Min': 'Fwd Packet Length Min',\n",
    "    'Fwd Packet Length Mean': 'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std': 'Fwd Packet Length Std',\n",
    "    'Bwd Packet Length Max': 'Bwd Packet Length Max',\n",
    "    'Bwd Packet Length Min': 'Bwd Packet Length Min',\n",
    "    'Bwd Packet Length Mean': 'Bwd Packet Length Mean',\n",
    "    'Bwd Packet Length Std': 'Bwd Packet Length Std',\n",
    "    'Flow Bytes/s': 'Flow Bytes/s',\n",
    "    'Flow Packets/s': 'Flow Packets/s',\n",
    "    'Flow IAT Mean': 'Flow IAT Mean',\n",
    "    'Flow IAT Std': 'Flow IAT Std',\n",
    "    'Flow IAT Max': 'Flow IAT Max',\n",
    "    'Flow IAT Min': 'Flow IAT Min',\n",
    "    'Fwd IAT Total': 'Fwd IAT Total',\n",
    "    'Fwd IAT Mean': 'Fwd IAT Mean',\n",
    "    'Fwd IAT Std': 'Fwd IAT Std',\n",
    "    'Fwd IAT Max': 'Fwd IAT Max',\n",
    "    'Fwd IAT Min': 'Fwd IAT Min',\n",
    "    'Bwd IAT Total': 'Bwd IAT Total',\n",
    "    'Bwd IAT Mean': 'Bwd IAT Mean',\n",
    "    'Bwd IAT Std': 'Bwd IAT Std',\n",
    "    'Bwd IAT Max': 'Bwd IAT Max',\n",
    "    'Bwd IAT Min': 'Bwd IAT Min',\n",
    "    'Fwd Header Length': 'Fwd Header Length',\n",
    "    'Bwd Header Length': 'Bwd Header Length',\n",
    "    'Fwd Packets/s': 'Fwd Packets/s',\n",
    "    'Bwd Packets/s': 'Bwd Packets/s',\n",
    "    'Min Packet Length': 'Min Packet Length',\n",
    "    'Max Packet Length': 'Max Packet Length',\n",
    "    'Packet Length Mean': 'Packet Length Mean',\n",
    "    'Packet Length Std': 'Packet Length Std',\n",
    "    'Packet Length Variance': 'Packet Length Variance',\n",
    "    'FIN Flag Count': 'FIN Flag Count',\n",
    "    'PSH Flag Count': 'PSH Flag Count',\n",
    "    'ACK Flag Count': 'ACK Flag Count',\n",
    "    'Average Packet Size': 'Average Packet Size',\n",
    "    'Subflow Fwd Bytes': 'Subflow Fwd Bytes',\n",
    "    'Init_Win_bytes_forward': 'Init_Win_bytes_forward',\n",
    "    'Init_Win_bytes_backward': 'Init_Win_bytes_backward',\n",
    "    'act_data_pkt_fwd': 'act_data_pkt_fwd',\n",
    "    'min_seg_size_forward': 'min_seg_size_forward',\n",
    "    'Active Mean': 'Active Mean',\n",
    "    'Active Max': 'Active Max',\n",
    "    'Active Min': 'Active Min',\n",
    "    'Idle Mean': 'Idle Mean',\n",
    "    'Idle Max': 'Idle Max',\n",
    "    'Idle Min': 'Idle Min'\n",
    "}\n",
    "\n",
    "final_columns_df2 = {\n",
    "    'Dst Port': 'Destination Port',\n",
    "    'Flow Duration': 'Flow Duration',\n",
    "    'Total Fwd Packet': 'Total Fwd Packets',\n",
    "    'Total Length of Fwd Packet': 'Total Length of Fwd Packets',\n",
    "    'Fwd Packet Length Max': 'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Min': 'Fwd Packet Length Min',\n",
    "    'Fwd Packet Length Mean': 'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std': 'Fwd Packet Length Std',\n",
    "    'Bwd Packet Length Max': 'Bwd Packet Length Max',\n",
    "    'Bwd Packet Length Min': 'Bwd Packet Length Min',\n",
    "    'Bwd Packet Length Mean': 'Bwd Packet Length Mean',\n",
    "    'Bwd Packet Length Std': 'Bwd Packet Length Std',\n",
    "    'Flow Bytes/s': 'Flow Bytes/s',\n",
    "    'Flow Packets/s': 'Flow Packets/s',\n",
    "    'Flow IAT Mean': 'Flow IAT Mean',\n",
    "    'Flow IAT Std': 'Flow IAT Std',\n",
    "    'Flow IAT Max': 'Flow IAT Max',\n",
    "    'Flow IAT Min': 'Flow IAT Min',\n",
    "    'Fwd IAT Total': 'Fwd IAT Total',\n",
    "    'Fwd IAT Mean': 'Fwd IAT Mean',\n",
    "    'Fwd IAT Std': 'Fwd IAT Std',\n",
    "    'Fwd IAT Max': 'Fwd IAT Max',\n",
    "    'Fwd IAT Min': 'Fwd IAT Min',\n",
    "    'Bwd IAT Total': 'Bwd IAT Total',\n",
    "    'Bwd IAT Mean': 'Bwd IAT Mean',\n",
    "    'Bwd IAT Std': 'Bwd IAT Std',\n",
    "    'Bwd IAT Max': 'Bwd IAT Max',\n",
    "    'Bwd IAT Min': 'Bwd IAT Min',\n",
    "    'Fwd Header Length': 'Fwd Header Length',\n",
    "    'Bwd Header Length': 'Bwd Header Length',\n",
    "    'Fwd Packets/s': 'Fwd Packets/s',\n",
    "    'Bwd Packets/s': 'Bwd Packets/s',\n",
    "    'Packet Length Min': 'Min Packet Length',\n",
    "    'Packet Length Max': 'Max Packet Length',\n",
    "    'Packet Length Mean': 'Packet Length Mean',\n",
    "    'Packet Length Std': 'Packet Length Std',\n",
    "    'Packet Length Variance': 'Packet Length Variance',\n",
    "    'FIN Flag Count': 'FIN Flag Count',\n",
    "    'PSH Flag Count': 'PSH Flag Count',\n",
    "    'ACK Flag Count': 'ACK Flag Count',\n",
    "    'Average Packet Size': 'Average Packet Size',\n",
    "    'Subflow Fwd Bytes': 'Subflow Fwd Bytes',\n",
    "    'FWD Init Win Bytes': 'Init_Win_bytes_forward',\n",
    "    'Bwd Init Win Bytes': 'Init_Win_bytes_backward',\n",
    "    'Fwd Act Data Pkts': 'act_data_pkt_fwd',\n",
    "    'Fwd Seg Size Min': 'min_seg_size_forward',\n",
    "    'Active Mean': 'Active Mean',\n",
    "    'Active Max': 'Active Max',\n",
    "    'Active Min': 'Active Min',\n",
    "    'Idle Mean': 'Idle Mean',\n",
    "    'Idle Max': 'Idle Max',\n",
    "    'Idle Min': 'Idle Min'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "098ea70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected number of features for the model: 52\n"
     ]
    }
   ],
   "source": [
    "df1_dos_standardized = df1_dos[list(final_columns_df1.keys())].rename(columns=final_columns_df1)\n",
    "df2_dos_standardized = df2_dos[list(final_columns_df2.keys())].rename(columns=final_columns_df2)\n",
    "df3_dos_standardized = df3_dos[list(final_columns_df1.keys())].rename(columns=final_columns_df1)\n",
    "print(\"expected number of features for the model:\", len(final_columns_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67387c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1_dos_standardized shape: (5499, 52)\n",
      "df2_dos_standardized shape: (659, 52)\n",
      "df3_dos_standardized shape: (376, 52)\n",
      "Expected number of features for the model: 52\n"
     ]
    }
   ],
   "source": [
    "print(\"df1_dos_standardized shape:\", df1_dos_standardized.shape)\n",
    "print(\"df2_dos_standardized shape:\",df2_dos_standardized.shape)\n",
    "print(\"df3_dos_standardized shape:\", df3_dos_standardized.shape)\n",
    "print(\"Expected number of features for the model:\", len(final_columns_df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78ca74",
   "metadata": {},
   "source": [
    "# Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de09e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wahba/miniconda3/envs/ml2/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/wahba/miniconda3/envs/ml2/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RobustScaler from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "rf = joblib.load(\"/home/wahba/Documents/models_anacletu/xgboost.joblib\")\n",
    "xgb = joblib.load(\"/home/wahba/Documents/models_anacletu/xgboost.joblib\")\n",
    "knn = joblib.load(\"/home/wahba/Documents/models_anacletu/knn_model.joblib\")\n",
    "robust_scaler = joblib.load(\"/home/wahba/Documents/models_anacletu/robust_scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f73263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[0 1 2 3 4 5 6]\n",
      "['Bots' 'Brute Force' 'DDoS' 'DoS' 'Normal Traffic' 'Port Scanning'\n",
      " 'Web Attacks']\n"
     ]
    }
   ],
   "source": [
    "print(rf.classes_)\n",
    "print(xgb.classes_)\n",
    "print(knn.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06a5d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_df1 = rf.predict(df1_dos_standardized)\n",
    "xgb_predictions_df1 = xgb.predict(df1_dos_standardized)\n",
    "knn_predictions_df1 = knn.predict(robust_scaler.transform(df1_dos_standardized))\n",
    "\n",
    "rf_predictions_df2 = rf.predict(df2_dos_standardized)\n",
    "xgb_predictions_df2 = xgb.predict(df2_dos_standardized)\n",
    "knn_predictions_df2 = knn.predict(robust_scaler.transform(df2_dos_standardized))\n",
    "\n",
    "rf_predictions_df3 = rf.predict(df3_dos_standardized)\n",
    "xgb_predictions_df3 = xgb.predict(df3_dos_standardized)\n",
    "knn_predictions_df3 = knn.predict(robust_scaler.transform(df3_dos_standardized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b55c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Count                                                \\\n",
      "Class              0       1    3    5 DDoS     DoS Normal Traffic   \n",
      "Dataset Model                                                        \n",
      "df1     KNN      NaN     NaN  NaN  NaN  1.0  5308.0          189.0   \n",
      "        RF       4.0  5493.0  1.0  1.0  NaN     NaN            NaN   \n",
      "        XGB      4.0  5493.0  1.0  1.0  NaN     NaN            NaN   \n",
      "df2     KNN      NaN     NaN  NaN  NaN  2.0   380.0          277.0   \n",
      "        RF       NaN   659.0  NaN  NaN  NaN     NaN            NaN   \n",
      "        XGB      NaN   659.0  NaN  NaN  NaN     NaN            NaN   \n",
      "df3     KNN      NaN     NaN  NaN  NaN  NaN   183.0          193.0   \n",
      "        RF     174.0   202.0  NaN  NaN  NaN     NaN            NaN   \n",
      "        XGB    174.0   202.0  NaN  NaN  NaN     NaN            NaN   \n",
      "\n",
      "                          Percentage                                   \\\n",
      "Class         Web Attacks          0       1     3     5  DDoS    DoS   \n",
      "Dataset Model                                                           \n",
      "df1     KNN           1.0        NaN     NaN   NaN   NaN  0.0%  96.5%   \n",
      "        RF            NaN       0.1%   99.9%  0.0%  0.0%   NaN    NaN   \n",
      "        XGB           NaN       0.1%   99.9%  0.0%  0.0%   NaN    NaN   \n",
      "df2     KNN           NaN        NaN     NaN   NaN   NaN  0.3%  57.7%   \n",
      "        RF            NaN        NaN  100.0%   NaN   NaN   NaN    NaN   \n",
      "        XGB           NaN        NaN  100.0%   NaN   NaN   NaN    NaN   \n",
      "df3     KNN           NaN        NaN     NaN   NaN   NaN   NaN  48.7%   \n",
      "        RF            NaN      46.3%   53.7%   NaN   NaN   NaN    NaN   \n",
      "        XGB           NaN      46.3%   53.7%   NaN   NaN   NaN    NaN   \n",
      "\n",
      "                                          \n",
      "Class         Normal Traffic Web Attacks  \n",
      "Dataset Model                             \n",
      "df1     KNN             3.4%        0.0%  \n",
      "        RF               NaN         NaN  \n",
      "        XGB              NaN         NaN  \n",
      "df2     KNN            42.0%         NaN  \n",
      "        RF               NaN         NaN  \n",
      "        XGB              NaN         NaN  \n",
      "df3     KNN            51.3%         NaN  \n",
      "        RF               NaN         NaN  \n",
      "        XGB              NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a summary dataframe\n",
    "results = []\n",
    "\n",
    "datasets = ['df1', 'df2', 'df3']\n",
    "models = ['rf', 'xgb', 'knn']\n",
    "predictions_dict = {\n",
    "    'df1': {'rf': rf_predictions_df1, 'xgb': xgb_predictions_df1, 'knn': knn_predictions_df1},\n",
    "    'df2': {'rf': rf_predictions_df2, 'xgb': xgb_predictions_df2, 'knn': knn_predictions_df2},\n",
    "    'df3': {'rf': rf_predictions_df3, 'xgb': xgb_predictions_df3, 'knn': knn_predictions_df3}\n",
    "}\n",
    "\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        preds = predictions_dict[dataset][model]\n",
    "        value_counts = pd.Series(preds.argmax(axis=1) if len(preds.shape) > 1 else preds).value_counts().sort_index()\n",
    "        \n",
    "        for class_label, count in value_counts.items():\n",
    "            results.append({\n",
    "                'Dataset': dataset,\n",
    "                'Model': model.upper(),\n",
    "                'Class': class_label,\n",
    "                'Count': count,\n",
    "                'Percentage': f\"{(count/len(preds)*100):.1f}%\"\n",
    "            })\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "print(summary_df.pivot_table(index=['Dataset', 'Model'], columns='Class', values=['Count', 'Percentage'], aggfunc='first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20e7bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_df1_pd = pd.Series(rf_predictions_df1)\n",
    "xgb_predictions_df1_pd = pd.Series(xgb_predictions_df1)\n",
    "knn_predictions_df1_pd = pd.Series(knn_predictions_df1)\n",
    "\n",
    "rf_predictions_df2_pd = pd.Series(rf_predictions_df2)\n",
    "xgb_predictions_df2_pd = pd.Series(xgb_predictions_df2)\n",
    "knn_predictions_df2_pd = pd.Series(knn_predictions_df2)\n",
    "\n",
    "rf_predictions_df3_pd = pd.Series(rf_predictions_df3)\n",
    "xgb_predictions_df3_pd = pd.Series(xgb_predictions_df3)\n",
    "knn_predictions_df3_pd = pd.Series(knn_predictions_df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54dca659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf preditions df1\n",
      " 1    5493\n",
      "0       4\n",
      "3       1\n",
      "5       1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "xgb preditions df1\n",
      " 1    5493\n",
      "0       4\n",
      "3       1\n",
      "5       1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "knn preditions df1\n",
      " DoS               5308\n",
      "Normal Traffic     189\n",
      "Web Attacks          1\n",
      "DDoS                 1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "rf preditions df2\n",
      " 1    659\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "xgb preditions df2\n",
      " 1    659\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "knn preditions df2\n",
      " DoS               380\n",
      "Normal Traffic    277\n",
      "DDoS                2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "rf preditions df3\n",
      " 1    202\n",
      "0    174\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "xgb preditions df3\n",
      " 1    202\n",
      "0    174\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "knn preditions df3\n",
      " Normal Traffic    193\n",
      "DoS               183\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"rf preditions df1\\n\",rf_predictions_df1_pd.value_counts(), \"\\n\")\n",
    "print(\"xgb preditions df1\\n\",xgb_predictions_df1_pd.value_counts(), \"\\n\")\n",
    "print(\"knn preditions df1\\n\",knn_predictions_df1_pd.value_counts(), \"\\n\")\n",
    "print(\"rf preditions df2\\n\",rf_predictions_df2_pd.value_counts(), \"\\n\")\n",
    "print(\"xgb preditions df2\\n\",xgb_predictions_df2_pd.value_counts(), \"\\n\")\n",
    "print(\"knn preditions df2\\n\",knn_predictions_df2_pd.value_counts(), \"\\n\")\n",
    "print(\"rf preditions df3\\n\",rf_predictions_df3_pd.value_counts(), \"\\n\")\n",
    "print(\"xgb preditions df3\\n\",xgb_predictions_df3_pd.value_counts(), \"\\n\")\n",
    "print(\"knn preditions df3\\n\",knn_predictions_df3_pd.value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a9a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: DF1\n",
      "============================================================\n",
      "RF    : Avg Probability = 0.997 ± 0.024 (High Confidence: 99.9%)\n",
      "XGB   : Avg Probability = 0.997 ± 0.024 (High Confidence: 99.9%)\n",
      "KNN   : Avg Probability = 0.995 ± 0.038 (High Confidence: 100.0%)\n",
      "\n",
      "============================================================\n",
      "DATASET: DF2\n",
      "============================================================\n",
      "RF    : Avg Probability = 0.999 ± 0.011 (High Confidence: 100.0%)\n",
      "XGB   : Avg Probability = 0.999 ± 0.011 (High Confidence: 100.0%)\n",
      "KNN   : Avg Probability = 0.987 ± 0.068 (High Confidence: 100.0%)\n",
      "\n",
      "============================================================\n",
      "DATASET: DF3\n",
      "============================================================\n",
      "RF    : Avg Probability = 0.983 ± 0.051 (High Confidence: 100.0%)\n",
      "XGB   : Avg Probability = 0.983 ± 0.051 (High Confidence: 100.0%)\n",
      "KNN   : Avg Probability = 0.985 ± 0.069 (High Confidence: 100.0%)\n"
     ]
    }
   ],
   "source": [
    "def display_average_probabilities(predictions_dict):\n",
    "    \"\"\"\n",
    "    Display average probability of the predicted class for each model and dataset\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for dataset_name, models in predictions_dict.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DATASET: {dataset_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        for model_name, predictions in models.items():\n",
    "            # Get the predicted class and its probability\n",
    "            if len(predictions.shape) > 1:  # Multiclass probability array\n",
    "                predicted_classes = predictions.argmax(axis=1)\n",
    "                predicted_probs = predictions[np.arange(len(predictions)), predicted_classes]\n",
    "            else:  # Binary classification probabilities\n",
    "                predicted_classes = (predictions > 0.5).astype(int)\n",
    "                predicted_probs = np.where(predicted_classes == 1, predictions, 1 - predictions)\n",
    "            \n",
    "            avg_prob = predicted_probs.mean()\n",
    "            std_prob = predicted_probs.std()\n",
    "            confidence_ratio = (predicted_probs > 0.5).mean()  # % of predictions with >50% confidence\n",
    "            \n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Model': model_name.upper(),\n",
    "                'Avg_Probability': avg_prob,\n",
    "                'Std_Probability': std_prob,\n",
    "                'High_Confidence_Ratio': confidence_ratio,\n",
    "                'Samples': len(predictions)\n",
    "            })\n",
    "            \n",
    "            print(f\"{model_name.upper():<6}: Avg Probability = {avg_prob:.3f} ± {std_prob:.3f} \"\n",
    "                  f\"(High Confidence: {confidence_ratio:.1%})\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Usage\n",
    "predictions_dict = {\n",
    "    'df1': {'rf': rf_predictions_df1, 'xgb': xgb_predictions_df1, 'knn': knn_predictions_df1},\n",
    "    'df2': {'rf': rf_predictions_df2, 'xgb': xgb_predictions_df2, 'knn': knn_predictions_df2},\n",
    "    'df3': {'rf': rf_predictions_df3, 'xgb': xgb_predictions_df3, 'knn': knn_predictions_df3}\n",
    "}\n",
    "\n",
    "summary_df = display_average_probabilities(predictions_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
